{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2.1: LSH from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mmh3\n",
      "  Using cached https://files.pythonhosted.org/packages/fa/7e/3ddcab0a9fcea034212c02eb411433db9330e34d626360b97333368b4052/mmh3-2.5.1.tar.gz\n",
      "Building wheels for collected packages: mmh3\n",
      "  Running setup.py bdist_wheel for mmh3 ... \u001b[?25lerror\n",
      "  Complete output from command /Users/alexander/anaconda3/bin/python -u -c \"import setuptools, tokenize;__file__='/private/var/folders/2k/shj0p2n928j7fjq528nlws040000gn/T/pip-install-cqewgyjx/mmh3/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\\r\\n', '\\n');f.close();exec(compile(code, __file__, 'exec'))\" bdist_wheel -d /private/var/folders/2k/shj0p2n928j7fjq528nlws040000gn/T/pip-wheel-z2xaa6eu --python-tag cp36:\n",
      "  running bdist_wheel\n",
      "  running build\n",
      "  running build_ext\n",
      "  building 'mmh3' extension\n",
      "  creating build\n",
      "  creating build/temp.macosx-10.7-x86_64-3.6\n",
      "  gcc -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/Users/alexander/anaconda3/include -arch x86_64 -I/Users/alexander/anaconda3/include -arch x86_64 -I/Users/alexander/anaconda3/include/python3.6m -c mmh3module.cpp -o build/temp.macosx-10.7-x86_64-3.6/mmh3module.o\n",
      "  warning: include path for stdlibc++ headers not found; pass '-std=libc++' on the command line to use the libc++ standard library instead [-Wstdlibcxx-not-found]\n",
      "  1 warning generated.\n",
      "  gcc -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/Users/alexander/anaconda3/include -arch x86_64 -I/Users/alexander/anaconda3/include -arch x86_64 -I/Users/alexander/anaconda3/include/python3.6m -c MurmurHash3.cpp -o build/temp.macosx-10.7-x86_64-3.6/MurmurHash3.o\n",
      "  warning: include path for stdlibc++ headers not found; pass '-std=libc++' on the command line to use the libc++ standard library instead [-Wstdlibcxx-not-found]\n",
      "  1 warning generated.\n",
      "  creating build/lib.macosx-10.7-x86_64-3.6\n",
      "  g++ -bundle -undefined dynamic_lookup -L/Users/alexander/anaconda3/lib -arch x86_64 -L/Users/alexander/anaconda3/lib -arch x86_64 -arch x86_64 build/temp.macosx-10.7-x86_64-3.6/mmh3module.o build/temp.macosx-10.7-x86_64-3.6/MurmurHash3.o -o build/lib.macosx-10.7-x86_64-3.6/mmh3.cpython-36m-darwin.so\n",
      "  clang: warning: libstdc++ is deprecated; move to libc++ with a minimum deployment target of OS X 10.9 [-Wdeprecated]\n",
      "  ld: library not found for -lstdc++\n",
      "  clang: error: linker command failed with exit code 1 (use -v to see invocation)\n",
      "  error: command 'g++' failed with exit status 1\n",
      "  \n",
      "  ----------------------------------------\n",
      "\u001b[31m  Failed building wheel for mmh3\u001b[0m\n",
      "\u001b[?25h  Running setup.py clean for mmh3\n",
      "Failed to build mmh3\n",
      "Installing collected packages: mmh3\n",
      "  Running setup.py install for mmh3 ... \u001b[?25lerror\n",
      "    Complete output from command /Users/alexander/anaconda3/bin/python -u -c \"import setuptools, tokenize;__file__='/private/var/folders/2k/shj0p2n928j7fjq528nlws040000gn/T/pip-install-cqewgyjx/mmh3/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\\r\\n', '\\n');f.close();exec(compile(code, __file__, 'exec'))\" install --record /private/var/folders/2k/shj0p2n928j7fjq528nlws040000gn/T/pip-record-2fh8_ma3/install-record.txt --single-version-externally-managed --compile:\n",
      "    running install\n",
      "    running build\n",
      "    running build_ext\n",
      "    building 'mmh3' extension\n",
      "    creating build\n",
      "    creating build/temp.macosx-10.7-x86_64-3.6\n",
      "    gcc -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/Users/alexander/anaconda3/include -arch x86_64 -I/Users/alexander/anaconda3/include -arch x86_64 -I/Users/alexander/anaconda3/include/python3.6m -c mmh3module.cpp -o build/temp.macosx-10.7-x86_64-3.6/mmh3module.o\n",
      "    warning: include path for stdlibc++ headers not found; pass '-std=libc++' on the command line to use the libc++ standard library instead [-Wstdlibcxx-not-found]\n",
      "    1 warning generated.\n",
      "    gcc -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/Users/alexander/anaconda3/include -arch x86_64 -I/Users/alexander/anaconda3/include -arch x86_64 -I/Users/alexander/anaconda3/include/python3.6m -c MurmurHash3.cpp -o build/temp.macosx-10.7-x86_64-3.6/MurmurHash3.o\n",
      "    warning: include path for stdlibc++ headers not found; pass '-std=libc++' on the command line to use the libc++ standard library instead [-Wstdlibcxx-not-found]\n",
      "    1 warning generated.\n",
      "    creating build/lib.macosx-10.7-x86_64-3.6\n",
      "    g++ -bundle -undefined dynamic_lookup -L/Users/alexander/anaconda3/lib -arch x86_64 -L/Users/alexander/anaconda3/lib -arch x86_64 -arch x86_64 build/temp.macosx-10.7-x86_64-3.6/mmh3module.o build/temp.macosx-10.7-x86_64-3.6/MurmurHash3.o -o build/lib.macosx-10.7-x86_64-3.6/mmh3.cpython-36m-darwin.so\n",
      "    clang: warning: libstdc++ is deprecated; move to libc++ with a minimum deployment target of OS X 10.9 [-Wdeprecated]\n",
      "    ld: library not found for -lstdc++\n",
      "    clang: error: linker command failed with exit code 1 (use -v to see invocation)\n",
      "    error: command 'g++' failed with exit status 1\n",
      "    \n",
      "    ----------------------------------------\n",
      "\u001b[31mCommand \"/Users/alexander/anaconda3/bin/python -u -c \"import setuptools, tokenize;__file__='/private/var/folders/2k/shj0p2n928j7fjq528nlws040000gn/T/pip-install-cqewgyjx/mmh3/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\\r\\n', '\\n');f.close();exec(compile(code, __file__, 'exec'))\" install --record /private/var/folders/2k/shj0p2n928j7fjq528nlws040000gn/T/pip-record-2fh8_ma3/install-record.txt --single-version-externally-managed --compile\" failed with error code 1 in /private/var/folders/2k/shj0p2n928j7fjq528nlws040000gn/T/pip-install-cqewgyjx/mmh3/\u001b[0m\n",
      "\u001b[33mYou are using pip version 18.0, however version 18.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install mmh3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmh3 import hash  # murmur hash \n",
    "from random import randint\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Зададим игрушечный корпус документов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\n",
    "          \"Who was the first king of Poland\",\n",
    "          \"Who was the first ruler of Poland\",\n",
    "          \"Who was the last pharaoh of Egypt\", \n",
    "        ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Опишем функцию шинглирования корпуса.\n",
    "\n",
    "Шинглирование может происходит по словам и по словесным нграммам, также добавим возможность хешировать на лету слова/нграммы. Это позволит работать со словами вне словаря и сократить размер признакового пространства. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shingling(corpus, k=0, hash_shingles=False, buckets=2**15):\n",
    "    # corpus = list of strings\n",
    "    # k - size of char-ngrams for shingling\n",
    "    # hash_shingles - use shingle hashing or not\n",
    "    # buckets - num of buckets for hashing if hash_shingles=True\n",
    "    \n",
    "    if k:\n",
    "        shingled_corpus = [[phrase[i:i+k] for i in range(len(phrase) - k+1) ] for phrase in corpus]\n",
    "    \n",
    "    else: #if k = 0 - use words as shingles\n",
    "        shingled_corpus = [phrase.split() for phrase in corpus]\n",
    "    \n",
    "    if hash_shingles: \n",
    "        shingled_corpus = [[mmh.hash(shingle, signed=False) % buckets for shingle in doc] for doc in shingled_corpus]\n",
    "    \n",
    "    return shingled_corpus\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "shingled_corpus = shingling(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Who', 'was', 'the', 'first', 'king', 'of', 'Poland'],\n",
       " ['Who', 'was', 'the', 'first', 'ruler', 'of', 'Poland'],\n",
       " ['Who', 'was', 'the', 'last', 'pharaoh', 'of', 'Egypt']]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shingled_corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Определим функцию, считающую коэффициент Жаккара между документами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_sim(l1, l2):\n",
    "    # l1, l2 - lists of tokens\n",
    "    s1 = set(l1)\n",
    "    s2 = set(l2)\n",
    "    \n",
    "    intersection_size = len(s1.intersection(s2))\n",
    "    union_size = len(s1.union(s2))\n",
    "    \n",
    "    return intersection_size/union_size\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc1, doc2 = shingled_corpus[:2]\n",
    "jaccard_sim(doc1, doc2)  # как и следовало ожидать"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Зададим функцию, генерирующую минхэш-сигнатуру"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_minhash_signature(doc, num_perm=100):\n",
    "    # doc - list of shinles\n",
    "    # num_perm - number of hash functions to use\n",
    "    \n",
    "    minhash_signature = []\n",
    "\n",
    "    for i in range(num_perm):\n",
    "        new_hash = lambda x: mmh.hash(str(x), signed=False) % (100000+i)  # хэш-функции должны быть разными\n",
    "        minhash = min([new_hash(shingle) for shingle in doc])  # take only minimum of hashed values\n",
    "        minhash_signature.append(minhash)\n",
    "        \n",
    "    return minhash_signature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем сгенерировать минхэш-сигнатуру для первого и второго документа в коллекции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mmh' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-a87f8e3b9e04>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmhash_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m12\u001b[0m  \u001b[0;31m# 12 hash functions to use\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mminhash_doc0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_minhash_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshingled_corpus\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmhash_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mminhash_doc1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_minhash_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshingled_corpus\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmhash_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-53-11daff0f3c7c>\u001b[0m in \u001b[0;36mgenerate_minhash_signature\u001b[0;34m(doc, num_perm)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_perm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mnew_hash\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmmh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhash\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigned\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m100000\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# хэш-функции должны быть разными\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mminhash\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_hash\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshingle\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mshingle\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# take only minimum of hashed values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mminhash_signature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mminhash\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-53-11daff0f3c7c>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_perm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mnew_hash\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmmh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhash\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigned\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m100000\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# хэш-функции должны быть разными\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mminhash\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_hash\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshingle\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mshingle\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# take only minimum of hashed values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mminhash_signature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mminhash\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-53-11daff0f3c7c>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_perm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mnew_hash\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmmh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhash\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigned\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m100000\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# хэш-функции должны быть разными\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mminhash\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_hash\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshingle\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mshingle\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# take only minimum of hashed values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mminhash_signature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mminhash\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'mmh' is not defined"
     ]
    }
   ],
   "source": [
    "mhash_size = 12  # 12 hash functions to use\n",
    " \n",
    "minhash_doc0 = generate_minhash_signature(shingled_corpus[0], mhash_size)  \n",
    "minhash_doc1 = generate_minhash_signature(shingled_corpus[1], mhash_size)\n",
    "\n",
    "print(minhash_doc0)\n",
    "print(minhash_doc1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заметим, что здесь считать коэффициент Жаккара нужно, сравнивая элементы попарно, а не мешая их в одно множество"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_sim_mhash(l1, l2):\n",
    "    # l1, l2 - lists of minhashes\n",
    "    l1 = np.array(l1)\n",
    "    l2 = np.array(l2)\n",
    "    \n",
    "    intersection = (l1 == l2).sum()\n",
    "    \n",
    "    return intersection/l1.size\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'minhash_doc0' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-913a03f472d7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mjaccard_sim_mhash\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mminhash_doc0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminhash_doc1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'minhash_doc0' is not defined"
     ]
    }
   ],
   "source": [
    "jaccard_sim_mhash(minhash_doc0, minhash_doc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Примерно оценить размер группы и количество групп можно, исходя из того порога коэффициента Жаккара, который мы зададим для \"похожих\" документов\n",
    "\n",
    "Будем считать \"похожими\" документы с коэффициентов Жаккара, большим 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mhash_size = 12\n",
    "n = 4\n",
    "b = mhash_size/n #  количество групп\n",
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При выбранных $n$ и $b$ порог должен быть примерно равен ${1\\over b}^{1\\over n}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7598356856515925"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(1/b)**(1/n) #  больше 0.7 - значит группы, размера 4 подойдут"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Теперь опишем функцию, разбивающую сигнатуры по группам "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_supershingles(signature, n=4):\n",
    "    # signature - list of minhashes\n",
    "    return [signature[i:i+n] for i in range(0,len(signature),n)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'minhash_doc0' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-7d59a6c9d87c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mminhash_doc0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_supershingles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mminhash_doc0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'minhash_doc0' is not defined"
     ]
    }
   ],
   "source": [
    "print(minhash_doc0)\n",
    "print(get_supershingles(minhash_doc0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Теперь каждая группа - ключ, по которому можно искать похожие документы в хеш-таблице\n",
    "\n",
    "При наличии хотя бы одной совпадающей группы минхэшей в запросе и обработанном корпусе, запрос и соответствующий документ считаются потенциально похожей парой документов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте заведем такую хеш-таблицу, которая будет хранить информацию о корпусе.\n",
    "Заметим, что строго говоря, группа минхешей **неинвариантна относительно местонахождения**\n",
    "\n",
    "\n",
    "Проще на примере:\n",
    "- l1 =  (  [2,1,1]   [3,3,4]   )\n",
    "- l2 =  (  [1,2,3]   [2,1,1]   )\n",
    "\n",
    "Группа [2,1,1] есть в обоих сигнатурах, но помним, что сранивать сигнатуры в данном случае нужно попарно между собой. Таким образом общая группа в одном и в другом случаях отражает разные преобразования входных данных.\n",
    "\n",
    "Попарное сравнение - дает коэффициент Жаккара = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так что будем при формировании хеш-таблицы учитывать порядковый номер следования группы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Who', 'was', 'the', 'first', 'king', 'of', 'Poland'],\n",
       " ['Who', 'was', 'the', 'first', 'ruler', 'of', 'Poland'],\n",
       " ['Who', 'was', 'the', 'last', 'pharaoh', 'of', 'Egypt']]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shingled_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Параметры\n",
    "params = {'mhash_size': 12, \"n\":4, \"k_shingles\":0, \"hash_shingles\":False, \"buckets\":2**15}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lsh_training(corpus, parameters):\n",
    "    \"\"\"shingled_corpus - list of lists with documents' shingles\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    lsh_dict = {}\n",
    "    \n",
    "    shingled_corpus = shingling(corpus, parameters[\"k_shingles\"], \n",
    "                                parameters[\"hash_shingles\"], \n",
    "                                parameters[\"buckets\"])\n",
    "    \n",
    "    for doc_id, doc in enumerate(shingled_corpus):\n",
    "        minhash_signature = generate_minhash_signature(doc, num_perm=parameters[\"mhash_size\"])\n",
    "        minhash_groups = get_supershingles(minhash_signature, n=parameters[\"n\"])\n",
    "        \n",
    "        for i,group in enumerate(minhash_groups):\n",
    "            hash_key = hash(str(group),signed=False) % (100000+i)   # превращаем список с группой в строку, хешируем с учетом порядекового номера группы в сигнатуре \n",
    "            lsh_dict[hash_key] = corpus[doc_id]\n",
    "    \n",
    "    return lsh_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mmh' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-64-2a6f50caed4f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlsh_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlsh_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-63-7f910039ed5b>\u001b[0m in \u001b[0;36mlsh_training\u001b[0;34m(corpus, parameters)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mdoc_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshingled_corpus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mminhash_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_minhash_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_perm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"mhash_size\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mminhash_groups\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_supershingles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mminhash_signature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"n\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-53-11daff0f3c7c>\u001b[0m in \u001b[0;36mgenerate_minhash_signature\u001b[0;34m(doc, num_perm)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_perm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mnew_hash\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmmh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhash\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigned\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m100000\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# хэш-функции должны быть разными\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mminhash\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_hash\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshingle\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mshingle\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# take only minimum of hashed values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mminhash_signature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mminhash\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-53-11daff0f3c7c>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_perm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mnew_hash\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmmh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhash\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigned\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m100000\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# хэш-функции должны быть разными\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mminhash\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_hash\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshingle\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mshingle\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# take only minimum of hashed values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mminhash_signature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mminhash\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-53-11daff0f3c7c>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_perm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mnew_hash\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmmh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhash\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigned\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m100000\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# хэш-функции должны быть разными\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mminhash\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_hash\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshingle\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mshingle\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# take only minimum of hashed values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mminhash_signature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mminhash\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'mmh' is not defined"
     ]
    }
   ],
   "source": [
    "lsh_words = lsh_training(corpus, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lsh_words' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-65-eb588ddba6ce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlsh_words\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'lsh_words' is not defined"
     ]
    }
   ],
   "source": [
    "lsh_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Допустим теперь есть запрос и мы хотим найти максимально похожие документы в базе"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для запроса нужно провести все те же операции, чято и для документов в базе. Заметим, что набор хэш-функций **обязан остаться тем же самым**. Иначе все просто бессмысленно"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_similar(query, lsh_dict, parameters):\n",
    "    # query - document as string\n",
    "    possible_duplicates = set()\n",
    "    query = [query]\n",
    "    shingled_query = shingling(query, parameters[\"k_shingles\"], \n",
    "                                parameters[\"hash_shingles\"], \n",
    "                                parameters[\"buckets\"])  # параметры шинглирования должны быть те же, что и для корпуса\n",
    "    \n",
    "    query_signature = generate_minhash_signature(shingled_query[0], parameters[\"mhash_size\"])\n",
    "    query_groups = get_supershingles(query_signature, n=parameters[\"n\"])\n",
    "    \n",
    "    for i,group in enumerate(query_groups):\n",
    "        hash_key = hash(str(group),signed=False) % (100000+i)\n",
    "        if lsh_dict.get(hash_key):\n",
    "            possible_duplicates.add(lsh_dict[hash_key])\n",
    "\n",
    "    if possible_duplicates:\n",
    "        print(\"Possible duplicates for query:\")\n",
    "        for doc in possible_duplicates:\n",
    "            print(doc)\n",
    "            \n",
    "    else:\n",
    "        print(\"Duplicates for query not founded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lsh_words' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-67-be7859dae3d5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfind_similar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Who was the first king of\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlsh_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'lsh_words' is not defined"
     ]
    }
   ],
   "source": [
    "find_similar(\"Who was the first king of\", lsh_words, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lsh_words' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-68-2c479258d101>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfind_similar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Who was the first king of Polan\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlsh_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'lsh_words' is not defined"
     ]
    }
   ],
   "source": [
    "find_similar(\"Who was the first king of Polan\", lsh_words, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lsh_words' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-69-8307cecfc13a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfind_similar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Who was the last\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlsh_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'lsh_words' is not defined"
     ]
    }
   ],
   "source": [
    "find_similar(\"Who was the last\", lsh_words, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Шинглирование по нграммам помогает бороться с ошибками и опечатками в запросе"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Параметры\n",
    "params_ngrams = {'mhash_size': 12, \"n\":3, \"k_shingles\":5, \"hash_shingles\":False, \"buckets\":2**15}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mmh' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-71-876d2f1e517a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlsh_ngrams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlsh_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams_ngrams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-63-7f910039ed5b>\u001b[0m in \u001b[0;36mlsh_training\u001b[0;34m(corpus, parameters)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mdoc_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshingled_corpus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mminhash_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_minhash_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_perm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"mhash_size\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mminhash_groups\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_supershingles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mminhash_signature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"n\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-53-11daff0f3c7c>\u001b[0m in \u001b[0;36mgenerate_minhash_signature\u001b[0;34m(doc, num_perm)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_perm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mnew_hash\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmmh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhash\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigned\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m100000\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# хэш-функции должны быть разными\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mminhash\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_hash\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshingle\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mshingle\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# take only minimum of hashed values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mminhash_signature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mminhash\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-53-11daff0f3c7c>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_perm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mnew_hash\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmmh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhash\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigned\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m100000\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# хэш-функции должны быть разными\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mminhash\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_hash\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshingle\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mshingle\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# take only minimum of hashed values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mminhash_signature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mminhash\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-53-11daff0f3c7c>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_perm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mnew_hash\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmmh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhash\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigned\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m100000\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# хэш-функции должны быть разными\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mminhash\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_hash\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshingle\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mshingle\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# take only minimum of hashed values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mminhash_signature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mminhash\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'mmh' is not defined"
     ]
    }
   ],
   "source": [
    "lsh_ngrams = lsh_training(corpus, params_ngrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lsh_ngrams' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-72-1b84f91373ce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfind_similar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Who was the first king of Polan\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlsh_ngrams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams_ngrams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'lsh_ngrams' is not defined"
     ]
    }
   ],
   "source": [
    "find_similar(\"Who was the first king of Polan\", lsh_ngrams, params_ngrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lsh_ngrams' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-73-dce3d7545b3c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfind_similar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Who was the first king of Poand\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlsh_ngrams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams_ngrams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'lsh_ngrams' is not defined"
     ]
    }
   ],
   "source": [
    "find_similar(\"Who was the first king of Poand\", lsh_ngrams, params_ngrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lsh_ngrams' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-74-dbe16f333666>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfind_similar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"the first king of Poland\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlsh_ngrams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams_ngrams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'lsh_ngrams' is not defined"
     ]
    }
   ],
   "source": [
    "find_similar(\"the first king of Poland\", lsh_ngrams, params_ngrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SimHash"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simhash - алгоритм, альтернативный минхэшу - превратить последовательность шинглов в сигнатуру (только сигнатура получатется немного по другому). \n",
    "\n",
    "После получения сигнатуры выполняется LSH: разбиение сигнатуры на супершинглы, строится таблица дубликатов\n",
    "\n",
    "Основная идея состоит в том, что для каждого шингла формируются n-битные бинарные хеши, которые затем особым образом складываются"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Функция, получающая от шингла n_bit-ный бинарный хеш"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_binary_hash(s, n_bit=8):\n",
    "    binary_hash = (\"{0:0%sb}\"%str(n_bit)).format(hash(s, signed=False)%(2**n_bit-1))\n",
    "    return binary_hash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'signed' is an invalid keyword argument for this function",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-76-63c89914f604>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_binary_hash\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Hello!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-75-a4942260162f>\u001b[0m in \u001b[0;36mget_binary_hash\u001b[0;34m(s, n_bit)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_binary_hash\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_bit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mbinary_hash\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"{0:0%sb}\"\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_bit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhash\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigned\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mn_bit\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mbinary_hash\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'signed' is an invalid keyword argument for this function"
     ]
    }
   ],
   "source": [
    "get_binary_hash(\"Hello!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Функция, получающая из документа SimHash сигнатуру"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- получаем для шинглов обычный 32-битный integer хеш\n",
    "- хешируем его на **$2^{n\\_bit}-1$** bucket'ов, чтобы получить n_bit-ный бинарный хеш  \n",
    "- затем в бинарных хешах превращаем все 0 в -1\n",
    "- затем взвешиваем бинарные хеши для каждого шингла в соответствии с term-frequency для данного шингла (опционально)\n",
    "- затем побитово суммируем все хеши для каждого шингла\n",
    "- затем бинаризуем побитово суммарный хеш: если компонент > 0 - ставим 1, иначе - ставим 0\n",
    "- полученная сигнатура и есть SimHash сигнатура документа "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_simhash(doc, n_bit=8):\n",
    "    # doc - list of shingles    \n",
    "    hashes = [get_binary_hash(shingle, n_bit=n_bit) for shingle in doc] # get binary hashes for all shingles\n",
    "    hashes = np.array([[1 if bit == \"1\" else -1 for bit in bithash] for bithash in hashes])   # map 0 to -1 \n",
    "    simhash = np.array([1 if i>0 else 0 for i in hashes.sum(axis=0)]) # sum up all hashes bitwise and binarize final hash\n",
    "\n",
    "    return simhash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = corpus[0].split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'signed' is an invalid keyword argument for this function",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-79-88dac9870dd3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msimhash_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_simhash\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0msimhash_signature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-77-60e8493590aa>\u001b[0m in \u001b[0;36mget_simhash\u001b[0;34m(doc, n_bit)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_simhash\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_bit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m# doc - list of shingles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mhashes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mget_binary_hash\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshingle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_bit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_bit\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mshingle\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# get binary hashes for all shingles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mhashes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mbit\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"1\"\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mbit\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbithash\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mbithash\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhashes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# map 0 to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0msimhash\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhashes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# sum up all hashes bitwise and binarize final hash\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-77-60e8493590aa>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_simhash\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_bit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m# doc - list of shingles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mhashes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mget_binary_hash\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshingle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_bit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_bit\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mshingle\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# get binary hashes for all shingles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mhashes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mbit\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"1\"\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mbit\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbithash\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mbithash\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhashes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# map 0 to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0msimhash\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhashes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# sum up all hashes bitwise and binarize final hash\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-75-a4942260162f>\u001b[0m in \u001b[0;36mget_binary_hash\u001b[0;34m(s, n_bit)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_binary_hash\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_bit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mbinary_hash\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"{0:0%sb}\"\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_bit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhash\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigned\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mn_bit\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mbinary_hash\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'signed' is an invalid keyword argument for this function"
     ]
    }
   ],
   "source": [
    "simhash_signature = get_simhash(doc)\n",
    "simhash_signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'simhash_signature' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-80-4188e33964fc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_supershingles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msimhash_signature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'simhash_signature' is not defined"
     ]
    }
   ],
   "source": [
    "get_supershingles(simhash_signature, n=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Функция близости между векторами:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similarity(simhash1, simhash2):\n",
    "    # FYI: Hamming distance for bit vectors = number of different components for pair of vectors\n",
    "    # Hamming([1,0,1,0,1], [1,0,1,0,0]) = 1 - only last bit differs\n",
    "    return (simhash1 == simhash2).sum() / len(simhash1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Какое сходство между первыми двумя документами корпуса?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'signed' is an invalid keyword argument for this function",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-82-eaa20b94eef7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdoc1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msimhash_signature1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_simhash\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdoc2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0msimhash_signature2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_simhash\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-77-60e8493590aa>\u001b[0m in \u001b[0;36mget_simhash\u001b[0;34m(doc, n_bit)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_simhash\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_bit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m# doc - list of shingles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mhashes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mget_binary_hash\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshingle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_bit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_bit\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mshingle\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# get binary hashes for all shingles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mhashes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mbit\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"1\"\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mbit\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbithash\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mbithash\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhashes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# map 0 to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0msimhash\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhashes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# sum up all hashes bitwise and binarize final hash\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-77-60e8493590aa>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_simhash\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_bit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m# doc - list of shingles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mhashes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mget_binary_hash\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshingle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_bit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_bit\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mshingle\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# get binary hashes for all shingles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mhashes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mbit\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"1\"\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mbit\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbithash\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mbithash\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhashes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# map 0 to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0msimhash\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhashes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# sum up all hashes bitwise and binarize final hash\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-75-a4942260162f>\u001b[0m in \u001b[0;36mget_binary_hash\u001b[0;34m(s, n_bit)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_binary_hash\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_bit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mbinary_hash\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"{0:0%sb}\"\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_bit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhash\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigned\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mn_bit\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mbinary_hash\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'signed' is an invalid keyword argument for this function"
     ]
    }
   ],
   "source": [
    "doc1 = corpus[0].split()\n",
    "simhash_signature1 = get_simhash(doc1)\n",
    "\n",
    "doc2 = corpus[1].split()\n",
    "simhash_signature2 = get_simhash(doc2)\n",
    "\n",
    "get_similarity(simhash_signature1, simhash_signature2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Они очень похожи с точки зрения Симхэша, даже более, чем с точки зрения Минхэш сигнатуры"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Давайте сделаем LSH с SimHash сигнатурой и посмотрим, что получится"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Параметры\n",
    "params = {\"n_bits\": 16, \"n\":4, \"k_shingles\":0, \"hash_shingles\":False, \"buckets\":2**15}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lsh_training(corpus, parameters):\n",
    "    \"\"\"shingled_corpus - list of lists with documents' shingles\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    lsh_dict = {}\n",
    "    \n",
    "    shingled_corpus = shingling(corpus, parameters[\"k_shingles\"], \n",
    "                                parameters[\"hash_shingles\"], \n",
    "                                parameters[\"buckets\"])\n",
    "    \n",
    "    for doc_id, doc in enumerate(shingled_corpus):\n",
    "        simhash_signature = get_simhash(doc, n_bit=parameters[\"n_bits\"])\n",
    "        simhash_groups = get_supershingles(simhash_signature, n=parameters[\"n\"])\n",
    "        \n",
    "        for i,group in enumerate(simhash_groups):\n",
    "            hash_key = hash(str(group),signed=False) % (100000+i)   # превращаем список с группой в строку, хешируем с учетом порядекового номера группы в сигнатуре \n",
    "            lsh_dict[hash_key] = corpus[doc_id]\n",
    "    \n",
    "    return lsh_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_similar(query, lsh_dict, parameters):\n",
    "    # query - document as string\n",
    "    possible_duplicates = set()\n",
    "    query = [query]\n",
    "    shingled_query = shingling(query, parameters[\"k_shingles\"], \n",
    "                                parameters[\"hash_shingles\"], \n",
    "                                parameters[\"buckets\"])  # параметры шинглирования должны быть те же, что и для корпуса\n",
    "    \n",
    "    query_signature = get_simhash(shingled_query[0], parameters[\"n_bits\"])\n",
    "    query_groups = get_supershingles(query_signature, n=parameters[\"n\"])\n",
    "    \n",
    "    for i,group in enumerate(query_groups):\n",
    "        hash_key = hash(str(group),signed=False) % (100000+i)\n",
    "        if lsh_dict.get(hash_key):\n",
    "            possible_duplicates.add(lsh_dict[hash_key])\n",
    "\n",
    "    if possible_duplicates:\n",
    "        print(\"Possible duplicates for query:\")\n",
    "        for doc in possible_duplicates:\n",
    "            print(doc)\n",
    "            \n",
    "    else:\n",
    "        print(\"Duplicates for query not founded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'signed' is an invalid keyword argument for this function",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-86-371351293141>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlsh_simhash_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlsh_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-84-3e4dcad01daf>\u001b[0m in \u001b[0;36mlsh_training\u001b[0;34m(corpus, parameters)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mdoc_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshingled_corpus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0msimhash_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_simhash\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_bit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"n_bits\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0msimhash_groups\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_supershingles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msimhash_signature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"n\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-77-60e8493590aa>\u001b[0m in \u001b[0;36mget_simhash\u001b[0;34m(doc, n_bit)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_simhash\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_bit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m# doc - list of shingles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mhashes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mget_binary_hash\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshingle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_bit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_bit\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mshingle\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# get binary hashes for all shingles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mhashes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mbit\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"1\"\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mbit\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbithash\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mbithash\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhashes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# map 0 to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0msimhash\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhashes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# sum up all hashes bitwise and binarize final hash\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-77-60e8493590aa>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_simhash\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_bit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m# doc - list of shingles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mhashes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mget_binary_hash\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshingle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_bit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_bit\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mshingle\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# get binary hashes for all shingles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mhashes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mbit\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"1\"\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mbit\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbithash\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mbithash\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhashes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# map 0 to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0msimhash\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhashes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# sum up all hashes bitwise and binarize final hash\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-75-a4942260162f>\u001b[0m in \u001b[0;36mget_binary_hash\u001b[0;34m(s, n_bit)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_binary_hash\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_bit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mbinary_hash\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"{0:0%sb}\"\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_bit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhash\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigned\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mn_bit\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mbinary_hash\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'signed' is an invalid keyword argument for this function"
     ]
    }
   ],
   "source": [
    "lsh_simhash_words = lsh_training(corpus, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lsh_simhash_words' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-87-b45fbcbbc167>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlsh_simhash_words\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'lsh_simhash_words' is not defined"
     ]
    }
   ],
   "source": [
    "lsh_simhash_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lsh_simhash_words' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-88-ef97898abcf3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfind_similar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"the first king of Poad\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlsh_simhash_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'lsh_simhash_words' is not defined"
     ]
    }
   ],
   "source": [
    "find_similar(\"the first king of Poad\", lsh_simhash_words, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lsh_simhash_words' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-89-84c31523da85>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfind_similar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"the last pharaoh of Eypt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlsh_simhash_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'lsh_simhash_words' is not defined"
     ]
    }
   ],
   "source": [
    "find_similar(\"the last pharaoh of Eypt\", lsh_simhash_words, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание:\n",
    "\n",
    "1) Реализуйте взвешивание бинарных хешей для шинглов с помощью TF(не надо нормализовывать на длину документа). Так как для данного корпуса это бессмысленно, возьмите корпус dorn_corpus с прошлого занятия\n",
    "\n",
    "2) Сделайте ф-ии lsh_training и find_similar универсальными, чтобы тип вычисления сигнатуры (MinHash, SimHash) можно было задавать параметром"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "dorn_corpus = [\"о боже мама мама я схожу с ума\", \n",
    "              \"ее улыбка мама кругом голова\",\n",
    "              \"о боже мама мама пьяный без вина\", \n",
    "              \"ее улыбка мама самая самая\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2.2: LSH - Quora queries similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting datasketch\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/70/9b/20349a2dcf02f68f0626e45eae33f07964a5a8e397ad370fce96d63ff975/datasketch-1.2.9-py2.py3-none-any.whl (64kB)\n",
      "\u001b[K    100% |████████████████████████████████| 71kB 1.5MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting redis>=2.10.0 (from datasketch)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3b/f6/7a76333cf0b9251ecf49efff635015171843d9b977e4ffcf59f9c4428052/redis-2.10.6-py2.py3-none-any.whl (64kB)\n",
      "\u001b[K    100% |████████████████████████████████| 71kB 10.3MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.11 in /Users/alexander/anaconda3/lib/python3.6/site-packages (from datasketch) (1.14.3)\n",
      "Installing collected packages: redis, datasketch\n",
      "Successfully installed datasketch-1.2.9 redis-2.10.6\n",
      "\u001b[33mYou are using pip version 18.0, however version 18.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install datasketch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Воспользуемся готовой реализацией"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import time\n",
    "from random import randint\n",
    "from datasketch import MinHash, MinHashLSHForest\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теже самые функции шинглирования для текста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocess will split a string of text into individual tokens/shingles based on whitespace.\n",
    "def shingling(text, k=7, hash_shingles=False, buckets=2**15):\n",
    "    text = text.lower()\n",
    "    if k:\n",
    "        shingled_text = [text[i:i+k] for i in range(len(text) - k+1) ]\n",
    "        \n",
    "    else: #if k = 0 - use words as shingles\n",
    "        shingled_text = text.split()\n",
    "    \n",
    "    if hash_shingles: \n",
    "        shingled_text = [hash(shingle, signed=False) % buckets for shingle in shingled_text]\n",
    "    \n",
    "    return shingled_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shingles (tokens) are: ['the dev', 'he devi', 'e devil', ' devil ', 'devil w', 'evil we', 'vil wen', 'il went', 'l went ', ' went d', 'went do', 'ent dow', 'nt down', 't down ', ' down t', 'down to', 'own to ', 'wn to g', 'n to ge', ' to geo', 'to geor', 'o georg', ' georgi', 'georgia']\n"
     ]
    }
   ],
   "source": [
    "text = 'The devil went down to Georgia'\n",
    "print('The shingles (tokens) are:', shingling(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_forest(corpus, perms):\n",
    "    \"\"\"\n",
    "    corpus - list of docs (each doc is string)\n",
    "    perms - number of permutations / of number of hash functions to use\n",
    "    returns LSH forest - more effective data structure for duplicates searching\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    \n",
    "    minhash = []\n",
    "    \n",
    "    for text in corpus:\n",
    "        shingles = shingling(text)\n",
    "        m = MinHash(num_perm=perms)\n",
    "        for shingle in shingles:\n",
    "            m.update(shingle.encode('utf8'))\n",
    "        minhash.append(m)\n",
    "        \n",
    "    forest = MinHashLSHForest(num_perm=perms)  # LSH forest - более эффективная структура для поиска дубликатов, нежели обычная хеш-таблица\n",
    "    \n",
    "    for i,m in enumerate(minhash):\n",
    "        forest.add(i,m)\n",
    "        \n",
    "    forest.index()\n",
    "    \n",
    "    print('It took %s seconds to build forest.' %(time.time() - start_time))\n",
    "    \n",
    "    return forest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(query, corpus, forest, num_results, perms):\n",
    "    \"\"\"\n",
    "    query - string of query for duplicates searching\n",
    "    corpus - list of docs (each doc is string) - as usual\n",
    "    perms - the same\n",
    "    num_results - top results for searching\n",
    "    forest - LSH forest structure for duplicates searching\n",
    "    returns num_results docs with maximal similarity to query\n",
    "    \"\"\"    \n",
    "    query_shingles = shingling(query)\n",
    "    m = MinHash(num_perm=perms)\n",
    "    for shingle in query_shingles:\n",
    "        m.update(shingle.encode('utf8'))\n",
    "        \n",
    "    idx_array = np.array(forest.query(m, num_results))\n",
    "    if len(idx_array) == 0:\n",
    "        return [] # if your query is empty, return none\n",
    "    \n",
    "    result = corpus[idx_array]\n",
    "    \n",
    "    dedupl_res = []\n",
    "    for res in result:\n",
    "        if (res != query) and (not res in dedupl_res):\n",
    "            dedupl_res.append(res)\n",
    "                \n",
    "    print('\\n Top Recommendations: \\n')\n",
    "\n",
    "    if len(dedupl_res):\n",
    "        for i,res in enumerate(dedupl_res):\n",
    "            print (i+1, res)\n",
    "    else:\n",
    "        print(\"No similar docs =(\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Протестируем, как это работает на \"Quora questions dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "      <td>What would happen if the Indian government sto...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "      <td>How can Internet speed be increased by hacking...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
       "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
       "      <td>Which fish would survive in salt water?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  qid1  qid2                                          question1  \\\n",
       "0   0     1     2  What is the step by step guide to invest in sh...   \n",
       "1   1     3     4  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
       "2   2     5     6  How can I increase the speed of my internet co...   \n",
       "3   3     7     8  Why am I mentally very lonely? How can I solve...   \n",
       "4   4     9    10  Which one dissolve in water quikly sugar, salt...   \n",
       "\n",
       "                                           question2  is_duplicate  \n",
       "0  What is the step by step guide to invest in sh...             0  \n",
       "1  What would happen if the Indian government sto...             0  \n",
       "2  How can Internet speed be increased by hacking...             0  \n",
       "3  Find the remainder when [math]23^{24}[/math] i...             0  \n",
       "4            Which fish would survive in salt water?             0  "
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/quora_data/train.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(404290, 6)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = pd.concat([df.question1, df.question2])  # concatenate 2 columns\n",
    "texts = pd.DataFrame(texts, columns=[\"text\"])\n",
    "texts = texts[pd.notnull(texts.text)]\n",
    "corpus = texts.text.values  # get only texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['What is the step by step guide to invest in share market in india?',\n",
       "       'What is the story of Kohinoor (Koh-i-Noor) Diamond?',\n",
       "       'How can I increase the speed of my internet connection while using a VPN?',\n",
       "       ..., \"What's this coin?\",\n",
       "       'I am having little hairfall problem but I want to use hair styling product. Which one should I prefer out of gel, wax and clay?',\n",
       "       'What is it like to have sex with your cousin?'], dtype=object)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Построим индекс:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It took 11213.811550855637 seconds to build forest.\n",
      "CPU times: user 15min 14s, sys: 24.4 s, total: 15min 38s\n",
      "Wall time: 3h 7min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Number of Permutations\n",
    "permutations = 128\n",
    "\n",
    "forest = get_forest(corpus, permutations)\n",
    "\n",
    "with open(\"data/quora_data/forest_dump.pkl\", 'wb') as f_obj:\n",
    "    pickle.dump(forest, f_obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создание структуры занимает достаточное время. Сохраним ее и загрузим из файла уже построенный индекс, чтобы сохранить время"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Файлик весит много, поэтому закину его отдельно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/sh: wget: command not found\n",
      "mv: forest_dump.pkl: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!wget https://t.bk.ru/aZgeg/forest_dump.pkl\n",
    "!mv forest_dump.pkl data/quora_data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/quora_data/forest_dump.pkl\", 'rb') as f_obj:\n",
    "    forest = pickle.load(f_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Протестируем поиск похожих, взяв в качестве запроса один из случайных документов корпуса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Top Recommendations: \n",
      "\n",
      "1 What are the best books about machine learning?\n",
      "2 What are the best books in machine learning?\n",
      "3 Which are the best books for machine learning?\n",
      "4 What are the most important Machine Learning algorithms?\n",
      "5 What are the best books for studying machine learning?\n"
     ]
    }
   ],
   "source": [
    "permutations = 128\n",
    "\n",
    "query = \"What are the best graduate schools for studying machine learning?\"\n",
    "result = predict(query, corpus, forest, num_results=10, perms=permutations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: How do you feel when your friend doesn't reply to your text message?\n",
      "\n",
      " Top Recommendations: \n",
      "\n",
      "1 How you feel when you graduate late than your friends?\n",
      "2 Do you feel there are too many trolls on Quora?\n",
      "3 How do you feel when your man notices attractive women?\n",
      "-------------------------\n",
      "Query: Why doesn't USA participate in Commonwealth Games?\n",
      "\n",
      " Top Recommendations: \n",
      "\n",
      "1 How and when was the Commonwealth of Nations created?\n",
      "2 What is the Commonwealth of Nations?\n",
      "3 What countries participate in The Commonwealth Games?\n",
      "-------------------------\n",
      "Query: Can you make Bisquick pancakes without eggs?\n",
      "\n",
      " Top Recommendations: \n",
      "\n",
      "1 How do you make whipped cream without heavy cream?\n",
      "2 How can you make pumpkin pie without using evaporated milk?\n",
      "-------------------------\n",
      "Query: What is the dumbest thing any country has ever done in a war?\n",
      "\n",
      " Top Recommendations: \n",
      "\n",
      "1 What is the dumbest thing the U.S government has ever done?\n",
      "2 What is the dumbest thing the U.S. government has ever done?\n",
      "3 What's the dumbest thing your cat has ever done?\n",
      "4 What is the dumbest thing your country has ever done?\n",
      "-------------------------\n",
      "Query: How long does it take until I can eat with bite blockers?\n",
      "\n",
      " Top Recommendations: \n",
      "\n",
      "1 How does it feel to be a part of group sex for the first time?\n",
      "2 When a body is immersed in a fluid, how is upthrust caused and why does it only act upwards?\n",
      "3 What are the risks of smoking weed (ganja)? Does it cause cancer?\n",
      "-------------------------\n"
     ]
    }
   ],
   "source": [
    "for _ in range(5):\n",
    "    rnd_idx = randint(0, len(corpus))\n",
    "    query = corpus[rnd_idx]\n",
    "    print(\"Query:\", query)\n",
    "    result = predict(query, corpus, forest, num_results=5, perms=permutations)\n",
    "    print('-------------------------')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
