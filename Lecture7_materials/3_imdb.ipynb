{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis for IMDB reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, HashingVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn import metrics\n",
    "seed = 42\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Имеются 25000 рецензий пользователей imdb с бинарными метками, посчитанными по оценкам: 0 при оценке < 5 и 1 при оценке >=7.\n",
    "\n",
    "Загрузим выборку:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 3)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb = pd.read_csv('data/imdb/labeledTrainData.tsv', delimiter='\\t')\n",
    "imdb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5814_8</td>\n",
       "      <td>1</td>\n",
       "      <td>With all this stuff going down at the moment w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2381_9</td>\n",
       "      <td>1</td>\n",
       "      <td>\\The Classic War of the Worlds\\\" by Timothy Hi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7759_3</td>\n",
       "      <td>0</td>\n",
       "      <td>The film starts with a manager (Nicholas Bell)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3630_4</td>\n",
       "      <td>0</td>\n",
       "      <td>It must be assumed that those who praised this...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9495_8</td>\n",
       "      <td>1</td>\n",
       "      <td>Superbly trashy and wondrously unpretentious 8...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  sentiment                                             review\n",
       "0  5814_8          1  With all this stuff going down at the moment w...\n",
       "1  2381_9          1  \\The Classic War of the Worlds\\\" by Timothy Hi...\n",
       "2  7759_3          0  The film starts with a manager (Nicholas Bell)...\n",
       "3  3630_4          0  It must be assumed that those who praised this...\n",
       "4  9495_8          1  Superbly trashy and wondrously unpretentious 8..."
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Классы сбалансированы:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    12500\n",
       "0    12500\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb.sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разобъём выборку на обучение и контроль:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_train, texts_test, y_train, y_test = train_test_split(imdb.review.values, imdb.sentiment.values, random_state=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Векторизуем тексты рецензий:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = TfidfVectorizer(sublinear_tf=True, use_idf=True)\n",
    "\n",
    "X_train = vect.fit_transform(texts_train,)\n",
    "X_test = vect.transform(texts_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Попробуйте выставить ngram_range = (1,3) в TfidfVectorizer. Сравните, как меняется качество классификации, время векторизации, обучения алгоритма и количества признаков\n",
    "\n",
    "2) Попробуйте применить HashingVectorizer. Сравните, как изменяется качество классификации, время обучения алгоритма"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Попробуем Наивного Байеса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.86416\n",
      "ROC-AUC:  0.9386419385416778\n"
     ]
    }
   ],
   "source": [
    "clf = MultinomialNB()\n",
    "clf.fit(X_train, y_train)\n",
    "print ('Accuracy: ', metrics.accuracy_score(y_test, clf.predict(X_test)))\n",
    "print ('ROC-AUC: ', metrics.roc_auc_score(y_test, clf.predict_proba(X_test)[:, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Не так уж и плохо"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Логистическая регрессия"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим на векторизованных данных логистическую регрессию и посчитаем точность и AUC:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8896\n",
      "ROC-AUC:  0.9603728226307936\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(solver='lbfgs', random_state=seed)\n",
    "clf.fit(X_train, y_train)\n",
    "print ('Accuracy: ', metrics.accuracy_score(y_test, clf.predict(X_test)))\n",
    "print ('ROC-AUC: ', metrics.roc_auc_score(y_test, clf.predict_proba(X_test)[:, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Признаков получилось очень много:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66639"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Проверим интерпретируемость полученных результатов:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Посмотрим топ-20 признаков с максимальными по модулю весами "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "worst -8.474879349682553\n",
      "bad -7.701620112098334\n",
      "great 7.230739970406239\n",
      "waste -5.75955034257617\n",
      "awful -5.563767379777922\n",
      "boring -5.489841365272624\n",
      "excellent 5.346736487756867\n",
      "best 4.751501510146608\n",
      "nothing -4.584306831142129\n",
      "poor -4.477863060482898\n",
      "terrible -4.420911700884977\n",
      "perfect 4.392495829725138\n",
      "worse -4.213536494042815\n",
      "wonderful 4.072026890216903\n",
      "love 3.9903977138367828\n",
      "no -3.967628756351888\n",
      "poorly -3.814419097999933\n",
      "amazing 3.790842662100928\n",
      "well 3.7857926701070235\n"
     ]
    }
   ],
   "source": [
    "for idx in np.argsort(np.abs(clf.coef_))[0,:-20:-1]:\n",
    "    # np.argsort сортирует clf.coef_ и возвращает сразу индексы соответствующих элементов в несортированном массиве \n",
    "    # (сортирует по возрастанию)\n",
    "    # np.abs - потому что хотим и положительные и отрицательные посмотреть\n",
    "    \n",
    "    # clf.coef_ - те самые веса для слов\n",
    "    print (vect.get_feature_names()[idx], clf.coef_[0, idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ну что ж  - вполне нормальные интерпретируемые токены"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Попробуем отбирать признаки с помощью l1 регуляризации:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 754\n",
      "Accuracy:  0.88256\n",
      "ROC-AUC:  0.9511075590278945\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(C=1, penalty='l1', solver=\"liblinear\")\n",
    "clf.fit(X_train, y_train)\n",
    "print (\"Number of features:\", np.sum(np.abs(clf.coef_) != 0))\n",
    "print ('Accuracy: ', metrics.accuracy_score(y_test, clf.predict(X_test)))\n",
    "print ('ROC-AUC: ', metrics.roc_auc_score(y_test, clf.predict_proba(X_test)[:, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Попробуем выбрать 100 наиболее информативных признаков по критерию Хи-квадрат"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector = SelectKBest(chi2, k=100)\n",
    "X_train_chi = selector.fit_transform(X_train, y_train)\n",
    "X_test_chi = selector.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.82624\n",
      "ROC-AUC:  0.9083672280997275\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(solver=\"lbfgs\", random_state=seed)\n",
    "clf.fit(X_train_chi, y_train)\n",
    "print ('Accuracy: ', metrics.accuracy_score(y_test, clf.predict(X_test_chi)))\n",
    "print ('ROC-AUC: ', metrics.roc_auc_score(y_test, clf.predict_proba(X_test_chi)[:, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Метод главных компонент"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сделаем 100 синтетических признаков с помощью метода t-SVD:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.92 s, sys: 731 ms, total: 6.65 s\n",
      "Wall time: 5.96 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "tsvd = TruncatedSVD(n_components=100, random_state=seed)\n",
    "X_train_svd = tsvd.fit_transform(X_train)\n",
    "X_test_svd = tsvd.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим на них логистическую регрессию:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.86016\n",
      "ROC-AUC:  0.9404743860845001\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(solver=\"lbfgs\")\n",
    "clf.fit(X_train_svd, y_train)\n",
    "print ('Accuracy: ', metrics.accuracy_score(y_test, clf.predict(X_test_svd)))\n",
    "print ('ROC-AUC: ', metrics.roc_auc_score(y_test, clf.predict_proba(X_test_svd)[:, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По 100 полученных таким способом признакам качество получается не намного хуже\n",
    "\n",
    "Попробуем обучить на них обучить случайный лес:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.83232\n",
      "ROC-AUC:  0.9092803283228205\n",
      "CPU times: user 14.3 s, sys: 92.5 ms, total: 14.4 s\n",
      "Wall time: 14.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_estimators=100)\n",
    "clf.fit(X_train_svd, y_train)\n",
    "print ('Accuracy: ', metrics.accuracy_score(y_test, clf.predict(X_test_svd)))\n",
    "print ('ROC-AUC: ', metrics.roc_auc_score(y_test, clf.predict_proba(X_test_svd)[:, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сравните качество и скорость обучения алгоритма"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовьте выборку для vowpal wabbit и обучите его. \n",
    "Сравните итоговые метрики, скорость работы. Поиграйтесь с гиперпараметрами, обучите логистическую регрессию и SVM (logloss и hinge loss), сравните качество работы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
