{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Подготовим данные, чтобы скормить фасттексту\n",
    "\n",
    "В каждой строчке после текста через tab должна стоять метка в формате \\__label__LABELNAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_label = '__label__positive'\n",
    "neg_label = '__label__negative'\n",
    "\n",
    "with open(join(DATA_OUT, 'fasttext_train.txt'), 'w') as f_out:\n",
    "\n",
    "    with open(join(DATA_DIR, 'train-pos.txt')) as f_in:\n",
    "        for line in f_in:\n",
    "            f_out.write(line.strip() + '\\t' + pos_label + '\\n')\n",
    "            \n",
    "    with open(join(DATA_DIR, 'train-neg.txt')) as f_in:\n",
    "        for line in f_in:\n",
    "            f_out.write(line.strip() + '\\t' + neg_label + '\\n')\n",
    "            \n",
    "with open(join(DATA_OUT, 'fasttext_test.txt'), 'w') as f_out:\n",
    "\n",
    "    with open(join(DATA_DIR, 'test-pos.txt')) as f_in:\n",
    "        for line in f_in:\n",
    "            f_out.write(line.strip() + '\\t' + pos_label + '\\n')\n",
    "            \n",
    "    with open(join(DATA_DIR, 'test-neg.txt')) as f_in:\n",
    "        for line in f_in:\n",
    "            f_out.write(line.strip() + '\\t' + neg_label + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Перемешаем данные в произвольном порядке, \n",
    "\n",
    "так как сейчас мы сложили их так, что сначала идут позитивне примеры, потом негативные\n",
    "\n",
    "Это можно сделать bash-командой shuf, но она не везде работает =(\n",
    "\n",
    "Сделаем через pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(join(DATA_OUT, 'fasttext_train.txt'), sep='\\t', names=['text', 'label'])\n",
    "df_train = df_train.sample(frac=1)\n",
    "df_train.to_csv(join(DATA_OUT, 'fasttext_train.txt'), sep='\\t', index=None, header=None)\n",
    "\n",
    "df_test = pd.read_csv(join(DATA_OUT, 'fasttext_test.txt'), sep='\\t', names=['text', 'label'])\n",
    "df_test = df_test.sample(frac=1)\n",
    "df_test.to_csv(join(DATA_OUT, 'fasttext_test.txt'), sep='\\t', index=None, header=None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Параметры обучения:\n",
    "- -input - путь к данным для обучения\n",
    "- -output - где сохранить модель\n",
    "- -minn/-maxn - какого минимального/максимального порядка символьные нграммы хотим получить \n",
    "- -wordNgrams - порядок словесных нграмм\n",
    "- -dim - размерность итогового вектора\n",
    "- -epoch - количество эпох обучения (проходов по обучающей выборке)\n",
    "- -thread - количество воркеров\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Обучим модель.\n",
    "\n",
    "Сначала получим полную версию модели, потом сжатую"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 5M words\n",
      "Number of words:  137321\n",
      "Number of labels: 2\n",
      "Progress: 100.0% words/sec/thread:  260897 lr:  0.000000 loss:  0.485448 ETA:   0h 0m 0.693690 ETA:   0h 0m ETA:   0h 0m0.694440 ETA:   0h 0m ETA:   0h 0m ETA:   0h 0m0.694595 ETA:   0h 0m 0.694504 ETA:   0h 0m0.694352 ETA:   0h 0m0.690193 ETA:   0h 0m  0h 0m  0h 0m loss:  0.643213 ETA:   0h 0m ETA:   0h 0m ETA:   0h 0m  0h 0m0.605605 ETA:   0h 0m ETA:   0h 0m  0h 0m 61.0% words/sec/thread:  259253 lr:  0.039021 loss:  0.572362 ETA:   0h 0m ETA:   0h 0m0.567099 ETA:   0h 0m 0.566124 ETA:   0h 0m ETA:   0h 0m0.539798 ETA:   0h 0m ETA:   0h 0m 0.512581 ETA:   0h 0m  0h 0m loss:  0.511471 ETA:   0h 0m0.507187 ETA:   0h 0m ETA:   0h 0m% words/sec/thread:  260798 lr:  0.011157 loss:  0.504786 ETA:   0h 0m 0.010667 loss:  0.504073 ETA:   0h 0m 0.503655 ETA:   0h 0m ETA:   0h 0m ETA:   0h 0m\n"
     ]
    }
   ],
   "source": [
    "!fasttext supervised -input data/fasttext_data/fasttext_train.txt -output data/fasttext_data/fasttext_model -minn 3 -maxn 6 -wordNgrams 2 -dim 100 -epoch 10 -thread 4 -verbose 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Получим сжатую версию модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "!fasttext quantize -input data/fasttext_data/fasttext_train.txt -output data/fasttext_data/fasttext_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Протестируем модель фасттекста на тестовых данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N\t25000\r\n",
      "P@1\t0.858\r\n",
      "R@1\t0.858\r\n",
      "Number of examples: 25000\r\n"
     ]
    }
   ],
   "source": [
    "!fasttext test data/fasttext_data/fasttext_model.ftz data/fasttext_data/fasttext_test.txt 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Фасттекст умеет предсказывать вероятности для конкретных примеров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head -10 data/fasttext_data/fasttext_test.txt > data/fasttext_data/test_input.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__label__positive 0.826598\r\n",
      "__label__positive 0.872829\r\n",
      "__label__positive 0.676666\r\n",
      "__label__negative 0.99175\r\n",
      "__label__positive 0.716987\r\n",
      "__label__positive 0.916417\r\n",
      "__label__negative 0.895252\r\n",
      "__label__positive 0.606333\r\n",
      "__label__negative 0.903834\r\n",
      "__label__negative 0.564985\r\n"
     ]
    }
   ],
   "source": [
    "!fasttext predict-prob data/fasttext_data/fasttext_model.ftz data/fasttext_data/test_input.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Сформируем отдельно выборки без меток и отдельно метки для получения векторов предложений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat data/fasttext_data/fasttext_train.txt | cut -f1 > data/fasttext_data/fasttext_train_no_labels.txt\n",
    "!cat data/fasttext_data/fasttext_train.txt | cut -f2 > data/fasttext_data/fasttext_train_labels.txt\n",
    "\n",
    "!cat data/fasttext_data/fasttext_test.txt | cut -f1 > data/fasttext_data/fasttext_test_no_labels.txt\n",
    "!cat data/fasttext_data/fasttext_test.txt | cut -f2 > data/fasttext_data/fasttext_test_labels.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Получим вектора для текстов обучающей и тестовой выборки\n",
    "print-sentence-vectors позволяет получить вектор для всего текста путем суммирования"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "!fasttext print-sentence-vectors data/fasttext_data/fasttext_model.ftz < data/fasttext_data/fasttext_train_no_labels.txt > data/fasttext_data/train_vectors.txt\n",
    "!fasttext print-sentence-vectors data/fasttext_data/fasttext_model.ftz < data/fasttext_data/fasttext_test_no_labels.txt > data/fasttext_data/test_vectors.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Подготовим выборки в виде numpy array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучающую:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = []\n",
    "with open('data/fasttext_data/train_vectors.txt') as f_in:\n",
    "    for line in f_in:\n",
    "        vector = [float(value) for value in line.strip().split()]\n",
    "        data_train.append(vector)\n",
    "        \n",
    "labels_train = []\n",
    "with open('data/fasttext_data/fasttext_train_labels.txt') as f_in:\n",
    "    for line in f_in:\n",
    "        if \"positive\" in line:\n",
    "            label = 1\n",
    "        else:\n",
    "            label = 0\n",
    "        labels_train.append(label)\n",
    "        \n",
    "data_train = np.array(data_train)\n",
    "labels_train = np.array(labels_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И тестовую:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = []\n",
    "with open('data/fasttext_data/test_vectors.txt') as f_in:\n",
    "    for line in f_in:\n",
    "        vector = [float(value) for value in line.strip().split()]\n",
    "        data_test.append(vector)\n",
    "        \n",
    "labels_test = []\n",
    "with open('data/fasttext_data/fasttext_test_labels.txt') as f_in:\n",
    "    for line in f_in:\n",
    "        if \"positive\" in line:\n",
    "            label = 1\n",
    "        else:\n",
    "            label = 0\n",
    "        labels_test.append(label)\n",
    "        \n",
    "data_test = np.array(data_test)\n",
    "labels_test = np.array(labels_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Обучим логрег над векторами текстов\n",
    "(каждая компонента вектора - отдельный признак)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='lbfgs',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = LogisticRegression(solver = 'lbfgs')\n",
    "classifier.fit(data_train, labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test = classifier.predict(data_test)  # предскажем класс"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Посчитаем метрики"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.85744\n",
      "Recall: 0.856960102342688\n"
     ]
    }
   ],
   "source": [
    "prec = precision_score(pred_test, labels_test) \n",
    "recall = recall_score(pred_test, labels_test)\n",
    "\n",
    "print(\"Precision:\", prec)\n",
    "print(\"Recall:\", recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Видим, что метрики получились почти те же самые, что и раньше"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Попробуем получить вектора для текстов unsupervised \n",
    "(так как у нас есть достаточный объем и неразмеченные данных), и потом уже на этих векторах обучить логрег, используя метки раразмеченной выборки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сольем все выборки в одну (и тестовые тексты, хотя так и нельзя)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat data/imdb_sentiment/train-* data/imdb_sentiment/test-* > data/fasttext_data/all_data.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Перемешаем выборку"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(join(DATA_OUT, 'all_data.txt'), names=['text'])\n",
    "df_train = df_train.sample(frac=1)\n",
    "df_train.to_csv(join(DATA_OUT, 'all_data.txt'), index=None, header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим скипграм модель _unsupervised_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 22M words\n",
      "Number of words:  343524\n",
      "Number of labels: 0\n",
      "Progress: 100.0% words/sec/thread:  101939 lr:  0.000000 loss:  0.690736 ETA:   0h 0m0h17mh13m11m10m  0h10mh 9mh 9mh 9m0h 9m0h 9m ETA:   0h 9mh 9mh 9m9m 8m 8mh 8mh 8m 8mh 8m  0h 8m 8m 8m8mh 8m  0h 8m8m 8mh 8m 8m0h 8m 8m8m0h 8m8mh 8m0h 8m0h 8mh 8m0h 8m0h 7m  0h 7mh 7m 7m0h 7m0h 7m0h 7m0h 7m  0h 7mh 7m  0h 7m  0h 7m0h 7mh 7m 0.037949 loss:  1.651968 ETA:   0h 7m  0h 7mh 7m0h 7m  0h 6m ETA:   0h 6m0h 6m 101063 lr:  0.036755 loss:  1.604143 ETA:   0h 6m0h 6m ETA:   0h 6mm 1.549834 ETA:   0h 6m  0h 6m 6m  0h 6m0h 6m6mh 6m 6m0h 6m 6m 6mh 6m6m 6m 33.3% words/sec/thread:  100937 lr:  0.033346 loss:  1.361672 ETA:   0h 6m0h 6m  0h 6mh 6m0h 6mh 6m 6m5m 5m 5m 5mm0h 5mh 5m  0h 5m 5m0h 5mh 5m5m5mh 5mh 5m  0h 5m0h 5mh 5m  0h 5mh 5mh 5mh 5m 5m0h 5m  0h 5m 5mh 5mh 5m  0h 5m  0h 5m0h 5m  0h 5m4mh 4m 4m0h 4m0h 4mh 4mh 4m0h 4mh 4m0h 4mh 4m  0h 4m ETA:   0h 4m0h 4m4mh 4m0h 4m0h 4mh 4m0h 4mh 4m0h 4m 4m  0h 4m56.0% words/sec/thread:  101439 lr:  0.022018 loss:  0.970440 ETA:   0h 4m 4m0h 4m0.961747 ETA:   0h 4m0h 4mh 3m 3mh 3mh 3m0h 3mh 3m0h 3m 3m0h 3m0h 3m  0h 3m3m3m3mmh 3mh 3m0h 3m 3m  0h 3m  0h 3m  0h 3m 3mh 3m  0h 2mh 2mh 2m 2m0h 2m  0h 2m0h 2mh 2m0h 2mh 2m0h 2mh 2mm 0.812443 ETA:   0h 2m0h 2m2mmh 2m0h 2m0h 2m 2m 1m0h 1mh 1mh 1mh 1m0h 1mh 1mh 1m 1mh 1m0h 1m 1mh 1mh 1m 1m ETA:   0h 1mh 1mh 1m0h 1m0h 1m1m0h 1m ETA:   0h 1m  0h 1mh 1m0.745288 ETA:   0h 1mh 1mh 1m 0mh 0m  0h 0mh 0m0h 0m0h 0mmh 0m0h 0m0m 0m  0h 0mh 0m0h 0m0h 0m 0.708290 ETA:   0h 0m  0h 0mh 0m0m0h 0m 0m0h 0m  0h 0m 0mmh 0m\n"
     ]
    }
   ],
   "source": [
    "!fasttext skipgram -input data/fasttext_data/all_data.txt -output data/fasttext_data/skipgram_model -minn 3 -maxn 6 -wordNgrams 2 -dim 100 -epoch 10 -minCount 1 -thread 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Предскажем вектора для текстов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "!fasttext print-sentence-vectors data/fasttext_data/skipgram_model.bin < data/fasttext_data/fasttext_train_no_labels.txt > data/fasttext_data/unsup_train_vectors.txt\n",
    "!fasttext print-sentence-vectors data/fasttext_data/skipgram_model.bin < data/fasttext_data/fasttext_test_no_labels.txt > data/fasttext_data/unsup_test_vectors.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подготовим выборки для классификатора"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = []\n",
    "with open('data/fasttext_data/unsup_train_vectors.txt') as f_in:\n",
    "    for line in f_in:\n",
    "        vector = [float(value) for value in line.strip().split()]\n",
    "        data_train.append(vector)\n",
    "        \n",
    "labels_train = []\n",
    "with open('data/fasttext_data/fasttext_train_labels.txt') as f_in:\n",
    "    for line in f_in:\n",
    "        if \"positive\" in line:\n",
    "            label = 1\n",
    "        else:\n",
    "            label = 0\n",
    "        labels_train.append(label)\n",
    "        \n",
    "data_train = np.array(data_train)\n",
    "labels_train = np.array(labels_train)\n",
    "\n",
    "\n",
    "data_test = []\n",
    "with open('data/fasttext_data/unsup_test_vectors.txt') as f_in:\n",
    "    for line in f_in:\n",
    "        vector = [float(value) for value in line.strip().split()]\n",
    "        data_test.append(vector)\n",
    "        \n",
    "labels_test = []\n",
    "with open('data/fasttext_data/fasttext_test_labels.txt') as f_in:\n",
    "    for line in f_in:\n",
    "        if \"positive\" in line:\n",
    "            label = 1\n",
    "        else:\n",
    "            label = 0\n",
    "        labels_test.append(label)\n",
    "        \n",
    "data_test = np.array(data_test)\n",
    "labels_test = np.array(labels_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим логрег над векторами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='lbfgs',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = LogisticRegression(solver = 'lbfgs')\n",
    "classifier.fit(data_train, labels_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Предскажем метки и посмотрим на метрики качества"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test = classifier.predict(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.85912\n",
      "Recall: 0.8628475012052065\n"
     ]
    }
   ],
   "source": [
    "prec = precision_score(pred_test, labels_test)\n",
    "recall = recall_score(pred_test, labels_test)\n",
    "\n",
    "print(\"Precision:\", prec)\n",
    "print(\"Recall:\", recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заметим, что вполне себе неплохо, хотя мы и не использовали информацию о метках при обучении векторов текстов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно еще заглянуть в vec-файлы. там тоже кое-что нужное и интересное =)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
