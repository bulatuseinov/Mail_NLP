{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install gensim   # установим библиотеку если еще не"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2 - Intruder detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Краткое описание задачи"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Будем решать задачу идентификации взломщика по его поведению в сети Интернет. В двух словах, взломщик будет себя вести не так, как владелец ящика: он может не удалять сообщения сразу по прочтении, как это делал хозяин, он будет по-другому ставить флажки сообщениям и даже по-своему двигать мышкой. Тогда такого злоумышленника можно идентифицировать и \"выкинуть\" из почтового ящика, предложив хозяину войти по SMS-коду.\n",
    "\n",
    "В этом соревновании будем решать похожую задачу: алгоритм будет анализировать последовательность из нескольких веб-сайтов, посещенных подряд одним и тем же человеком, и определять, это нормальный юзер или взломщик."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В обучающей выборке train_sessions.csv признаки site_i – это индексы посещенных сайтов (расшифровка дана в pickle-файле со словарем site_dic.pkl).\n",
    "Признаки time_j – время посещения сайтов site_j.\n",
    "\n",
    "Целевой признак target – факт того, что сессия принадлежит юзеру (то есть что именно юзер, а не взломщик ходил по всем этим сайтам).\n",
    "\n",
    "Задача – сделать прогнозы для сессий в тестовой выборке (test_sessions.csv), определить, принадлежат ли они реальному юзеру."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from gensim.models import word2vec\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# загрузим обучающую и тестовую выборки\n",
    "train_df = pd.read_csv('data/intruder_detection/train_sessions.csv')#,index_col='session_id')\n",
    "\n",
    "# приведем колонки time1, ..., time10 к временному формату\n",
    "times = ['time%s' % i for i in range(1, 11)]\n",
    "train_df[times] = train_df[times].apply(pd.to_datetime)\n",
    "\n",
    "# отсортируем данные по времени\n",
    "train_df = train_df.sort_values(by='time1')\n",
    "\n",
    "# посмотрим на кусочек обучающей выборки\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.target.sum()/train_df.shape[0]  # классы вообще не сбалансированы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sites = ['site%s' % i for i in range(1, 11)]\n",
    "#заменим nan на 0\n",
    "train_df[sites] = train_df[sites].fillna(0).astype('int').astype('str')\n",
    "\n",
    "#создадим псевдотексты необходимые для обучения word2vec\n",
    "train_df['list'] = train_df['site1']\n",
    "\n",
    "for s in sites[1:]:\n",
    "    train_df['list'] = train_df['list']+\",\"+train_df[s]\n",
    "\n",
    "train_df['list_w'] = train_df['list'].apply(lambda x: x.split(','))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# В нашем случае предложение это набор сайтов, которые посещал пользователь\n",
    "# нам необязательно переводить айдишники сайтов в названия, т.к. алгоритм будем выявлять их взаимосвязь друг с другом\n",
    "train_df['list_w'].iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# обучим нашу модель на всех данных \n",
    "# с размером окна=3(длина предложения 10 слов) и итоговыми векторами размерности 300, \n",
    "# параметр workers отвечает за количество ядер\n",
    "\n",
    "data = train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "vec_size = 300\n",
    "window_size = 3\n",
    "n_workers = 4\n",
    "model = word2vec.Word2Vec(data['list_w'], size=vec_size, window=window_size, workers=n_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#создадим словарь со \"словами\" и соответствующими им векторами\n",
    "w2v = dict(zip(model.wv.index2word, model.wv.syn0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В данной задаче под \"словом\" подразумевается айдишник сайта, а под \"предложением\" - последовательность посещения сайтов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Т.к. сейчас мы каждому \"слову\" сопоставили вектор, то нужно решить что сопоставить целому \"предложению\" из слов.\n",
    "Один из возможных вариантов это просто усреднить все слова в предложении и получить некоторый смысл всего предложения (если слова нет в тексте, то берем нулевой вектор)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mean_vectors(w2v_dict, data):\n",
    "        \n",
    "    return np.array([\n",
    "                        np.mean([w2v_dict[w] for w in sentence if w in w2v_dict] \n",
    "                        or [np.zeros(vec_size)], axis=0)\n",
    "                    for sentence in data\n",
    "                    \n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_mean = compute_mean_vectors(w2v, train_df['list_w'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_mean.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разобъем выборку на обучающую и валидационную"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_mean\n",
    "y = train_df.target.values\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, random_state=SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Применим сверху LogisticRegression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "lr = LogisticRegression(C=1, random_state=SEED, n_jobs=-1)\n",
    "\n",
    "# Обучение\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "# прогноз для валидационной выборки\n",
    "y_pred = lr.predict_proba(X_valid)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# считаем метрики\n",
    "score = roc_auc_score(y_valid, y_pred)\n",
    "\n",
    "print('ROC-AUC:', score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Попробуем взвесить вектора с idf весами"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем улучшить результаты."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь вместо обычного среднего, чтобы учесть частоту с которой слово встречается в тексте, возьмем взвешенное среднее. В качестве весов возьмем idf меру слова.  \n",
    "\n",
    "Idf это инверсия частоты, с которой некоторое слово встречается в других документах. Учёт idf уменьшает вес широкоупотребительных слов и увеличивает вес более уникальных слов, которые могут достаточно точно указать на то к какому классу относится текст. В нашем случае, кому принадлежит последовательность посещенных сайтов.\n",
    "$$idf(w,D)=log \\frac{|D|}{|{\\{d \\in D | w \\in d\\}}|}$$\n",
    "где $|D|$ - общее число документов, $\\{d \\in D | w \\in d\\}$ - число документов из $D$, в которых встречается слово $w$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidf_weighted_vectors(w2v_dict, data):\n",
    "        \n",
    "    tfidf = TfidfVectorizer(analyzer=lambda x: x)\n",
    "    tfidf.fit(data)\n",
    "    \n",
    "    max_idf = max(tfidf.idf_)\n",
    "    word2weight = defaultdict(\n",
    "                                lambda: max_idf,\n",
    "                                [(w, tfidf.idf_[i]) for w, i in tfidf.vocabulary_.items()]\n",
    "                    )\n",
    "    \n",
    "    return np.array([\n",
    "                        np.mean([w2v_dict[w] * word2weight[w] for w in sentence if w in w2v_dict] \n",
    "                        or [np.zeros(vec_size)], axis=0)\n",
    "                    for sentence in data\n",
    "                    \n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "data_tfidf_weighted = tfidf_weighted_vectors(w2v, train_df['list_w'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tfidf_weighted.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Опять разобъем выборку на обучающую и валидационную"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_tfidf_weighted\n",
    "y = train_df.target.values\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, random_state=SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим изменилось ли качество LogisticRegression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## считается долго (3 мин) - метрики чуть лучше\n",
    "%%time\n",
    "lr = LogisticRegression(C=1, random_state=SEED, n_jobs=-1)\n",
    "\n",
    "# Обучение\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "# прогноз для валидационной выборки\n",
    "y_pred = lr.predict_proba(X_valid)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# считаем метрики\n",
    "score = roc_auc_score(y_valid, y_pred)\n",
    "\n",
    "print('ROC-AUC:', score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим, что качество работы улучшилось.\n",
    "\n",
    "Значит взвешенное среднее помогает немного лучше отразить смысл всего предложения через word2vec, нежели простое усреднение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task3 - Предсказание популярности статьи на Хабре по ее содержанию"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Испробуем мощь word2vec на статьях Хабра."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from gensim.models import word2vec\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузим уже частично обработанную выборку\n",
    "\n",
    "В частности, таргет представлен в прологарифмированной форме. \n",
    "\n",
    "**Зачем ?** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://t.bk.ru/7Eyyw/train_small.csv \n",
    "!mv train_small.csv data/habr_task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "data_habr = pd.read_csv('data/habr_task/train_small.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_habr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_habr.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Будем обучать модель на всем содержании статьи. Для этого совершим некоторые преобразования над текстом."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напишем функцию, которая будет преобразовывать текстовую статью в лист из слов необходимый для обучения Word2Vec.\n",
    "Функция получает строку, в которой содержится весь текстовый документ.\n",
    "\n",
    "1) Сначала функция будет удалять все символы кроме букв верхнего и нижнего регистра;\n",
    "\n",
    "2) Затем преобразовывает слова к нижнему регистру и возвращает список слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def review_to_wordlist(review):\n",
    "    review_text = re.sub(\"[^а-яА-Яa-zA-Z]\",\" \", review)\n",
    "    words = review_text.lower().split()\n",
    "    return(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# если есть nan,преобразуем их к строке\n",
    "data_habr['content_clear'] = data_habr['content'].apply(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И наконец преобразуем контент статьи к списку слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "data_habr['content_clear'] = data_habr['content_clear'].apply(review_to_wordlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "## approx 3 min\n",
    "model = word2vec.Word2Vec(data_habr['content_clear'], size=300, window=5, workers=4)\n",
    "w2v = dict(zip(model.wv.index2word, model.wv.syn0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Считается достаточно долго, поэтому сохраним модель и будем подгружать ее впоследствии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "model.save(\"data/habr_task/word2vec.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "подгрузим модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://t.bk.ru/8B6cR/word2vec.model.trainables.syn1neg.npy\n",
    "!mv word2vec.model.trainables.syn1neg.npy data/habr_task/\n",
    "\n",
    "!wget https://t.bk.ru/UDb5P/word2vec.model.wv.vectors.npy\n",
    "!mv word2vec.model.wv.vectors.npy data/habr_task/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "model = word2vec.Word2Vec.load(\"data/habr_task/word2vec.model\")\n",
    "w2v = dict(zip(model.wv.index2word, model.wv.vectors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Теперь можно посмотреть, чему выучилась модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv.most_similar(positive=['привет'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv.most_similar(positive=['python'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv.most_similar(positive=['machine', 'learning'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv.most_similar(positive=['iphone'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ну что-то адекватное"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Давайте используем полученные вектора для предсказания рейтинга статьи"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_size = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mean_vectors(w2v_dict, data):\n",
    "        \n",
    "    return np.array([\n",
    "                        np.mean([w2v_dict[w] for w in sentence if w in w2v_dict] \n",
    "                        or [np.zeros(vec_size)], axis=0)\n",
    "                    for sentence in data\n",
    "                    \n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "## используем простое усреднение\n",
    "data_mean = compute_mean_vectors(w2v, data_habr['content_clear'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_mean\n",
    "y = data_habr['favs_lognorm']\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.1, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "ridge = Ridge(alpha=1, random_state=SEED)\n",
    "\n",
    "# Обучение\n",
    "ridge.fit(X_train, y_train)\n",
    "\n",
    "# прогноз для валидационной выборки\n",
    "y_pred = ridge.predict(X_valid)\n",
    "print('MSE на валидации', mean_squared_error(y_valid, y_pred))\n",
    "\n",
    "y_pred_train = ridge.predict(X_train)\n",
    "print('MSE на трейне', mean_squared_error(y_train, y_pred_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
