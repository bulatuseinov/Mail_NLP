{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Теоретические вопросы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*1) Какую роль выполняет функция активации в полносвязной нейросети? Также нужно пояснить, почему стакать несколько подряд идущих полносвязных слоев без активации не является хорошей практикой.* **0.5 балла**\n",
    "\n",
    "*2) Допустим у вас есть MLP (\"multi layer perceptron\" или полносвязная нейросеть) с 10-ю входными нейронами, за ними 50 нейронов в скрытом слое, на выходе 3 нейрона. Все нейроны снабжены функцией активации ReLU.* **1 балл**\n",
    "- Какова размерность матрицы $X$ на входе, если обучение проводится батчами. Размер батча $batch\\_size$\n",
    "- Какова размерность матрицы весов скрытого слоя $W_h$ и какова размерность вектора байеса $b_h$ этого скрытого слоя?\n",
    "- Какова размерность матрицы весов выходного слоя $W_o$ и какова размерность вектора байеса $b_o$ выходного слоя?\n",
    "- Какова размерность выходной матрицы $Y$?\n",
    "- Напишите как выглядит функция, которая считает выходную матрицу $Y$ как функцию от $X$, $W_h$, $W_o$, $b_h$, $b_o$.\n",
    "\n",
    "*3) Как устроено автоматическое дифференцирование в Tensorflow?* **0.5 балла**\n",
    "- Используются ли символьные вычисления?\n",
    "- Используется ли численное дифференцирование?\n",
    "- Сколько проходов по графу вычислений необходимо совершить,\n",
    "  чтобы посчитать градиенты для каждого параметра в Tensorflow?\n",
    "  \n",
    "*4) Что такое \"backpropagation\" и для чего он нужен. Чем он отличается от алгоритма градиентного спуска?* **0.5 балла**\n",
    "\n",
    "*5) Расскажите в чем отличия между mini-batch, batch, stochastic gradient descent. Какой из этих алгоритмов самый популярный и почему.* **0.5 балла**\n",
    "\n",
    "*6) Можно ли инициализировать первоначально все параметры обучаемой модели MLP единицами? А нулями? Поясните ваш ответ. Можно ли инициализировать нулями параметры $b_o$, $b_h$ из задачи №2?* **0.5 балла**\n",
    "\n",
    "*7) Вывести лосс-функцию кросс-энтропии из правдоподобия и из теории информации.* **0.5 балла**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Теоретические ответы\n",
    "\n",
    "    1. Добавляют нелинейность в нашу модель. Без них любая многослойная сеть = односойной, так как можно перемножить все эти матрицы и получить одну матрицу, которая будет давать точно такие же значений.\n",
    "\n",
    "    2.1 batch_size X 10\n",
    "    2.2 10 X batch_size, вектор баеса - (1, 10)^T\n",
    "    2.3 50 X batch_size, веткоp баеса - (1, 50)^T\n",
    "    2.4 batch_size X 3\n",
    "    2.5 Y = (ReLu(X * (W_h ^ b_h)) * (W_0 ^ b_0), ^ - присоединение \n",
    "\n",
    "    3. модуль tf.GradientTape используется для записи операций и для последующего вычисления градиента. Происходит два прохода, прямой и обратный, данные хранятся на tape. Для вычисления градиента, пленка воспроизводится в обратном порядке, а затем сбрасывается. Конкретная запись tf.GradientTape может произвести расчет только одного градиента; все последующие вызовы выдадут ошибку рабочей среды.\n",
    "    \n",
    "            4)Что такое \"backpropagation\" и для чего он нужен. Чем он отличается от алгоритма градиентного спуска? 0.5 балла. Алгоритм обратного распространения ошибки, можно сказать, что частный слйча градиентного спуска. Градиент на каждом шаге вычисляется с помощью правила взятия сложной производной, то есть мы умножаем градиент который пришел со слоя выша на производную в данном узле."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "5) Расскажите в чем отличия между mini-batch, batch, stochastic gradient descent. Какой из этих алгоритмов самый популярный и почему. 0.5 балла\n",
    "    0. batch -  обучаемся на всей выборке, сходится намного равномрнее двух других, но и считать много.\n",
    "    1. mini-batch - мы берем несколько элементов(subset) из выборки и обучаемся на них, сходится равномрнее SGD, но требует больше мощности вычислений.\n",
    "    2. SGD - берет один случайный обьекут обучающей выборки, медленне сходится(сильные флуктуации), но менее требователен к ресурсам, так как меньше вычислений.\n",
    "    \n",
    "    На вопрсо что самое популярное - я думаю зависит от задачи и мощности компьютера, я бы сказал, что mini batch или SGD так как они точно менее затратны и сходятся не сильно хуже и зачастую быстрее\n",
    "   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6) Можно ли инициализировать первоначально все параметры обучаемой модели MLP единицами? А нулями? Поясните ваш ответ. Можно ли инициализировать нулями параметры bobo, bhbh из задачи №2? 0.5 балла\n",
    "    1. единицами не пойдет - тогда все локальные градиенты будут одинаковыми и нейроны тоже одинаковые - бессмыслица\n",
    "    2. Нулями тоже не пойдет - так как градиенты будут 0 и веса не обновятся\n",
    "    3. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    \n",
    "    7) Из теории информации - расхождени Кульбака, для вычисления непохожести двух распределений. Оно определяется по следующей формуле: \n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "colab_type": "text",
    "id": "4f3CKqFUqL2-",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Первые шаги с TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MxiIKhP4E2Zr"
   },
   "source": [
    "[Описание данных](https://developers.google.com/machine-learning/crash-course/california-housing-data-description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rVFf5asKE2Zt"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "import tensorflow as tf\n",
    "from IPython.display import display, Math, Latex\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "pd.options.display.max_rows = 10\n",
    "pd.options.display.float_format = '{:.1f}'.format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ipRyUHjhU80Q"
   },
   "source": [
    "Подгружаем данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9ivCDWnwE2Zx"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>median_house_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6633</th>\n",
       "      <td>-114.3</td>\n",
       "      <td>34.2</td>\n",
       "      <td>15.0</td>\n",
       "      <td>5612.0</td>\n",
       "      <td>1283.0</td>\n",
       "      <td>1015.0</td>\n",
       "      <td>472.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>66.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9504</th>\n",
       "      <td>-114.5</td>\n",
       "      <td>34.4</td>\n",
       "      <td>19.0</td>\n",
       "      <td>7650.0</td>\n",
       "      <td>1901.0</td>\n",
       "      <td>1129.0</td>\n",
       "      <td>463.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>80.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11175</th>\n",
       "      <td>-114.6</td>\n",
       "      <td>33.7</td>\n",
       "      <td>17.0</td>\n",
       "      <td>720.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>333.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>1.7</td>\n",
       "      <td>85.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16226</th>\n",
       "      <td>-114.6</td>\n",
       "      <td>33.6</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1501.0</td>\n",
       "      <td>337.0</td>\n",
       "      <td>515.0</td>\n",
       "      <td>226.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>73.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6499</th>\n",
       "      <td>-114.6</td>\n",
       "      <td>33.6</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1454.0</td>\n",
       "      <td>326.0</td>\n",
       "      <td>624.0</td>\n",
       "      <td>262.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>65.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
       "6633      -114.3      34.2                15.0       5612.0          1283.0   \n",
       "9504      -114.5      34.4                19.0       7650.0          1901.0   \n",
       "11175     -114.6      33.7                17.0        720.0           174.0   \n",
       "16226     -114.6      33.6                14.0       1501.0           337.0   \n",
       "6499      -114.6      33.6                20.0       1454.0           326.0   \n",
       "\n",
       "       population  households  median_income  median_house_value  \n",
       "6633       1015.0       472.0            1.5                66.9  \n",
       "9504       1129.0       463.0            1.8                80.1  \n",
       "11175       333.0       117.0            1.7                85.7  \n",
       "16226       515.0       226.0            3.2                73.4  \n",
       "6499        624.0       262.0            1.9                65.5  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "california_housing_dataframe = pd.read_csv(\"https://download.mlcc.google.com/mledu-datasets/california_housing_train.csv\", sep=\",\")\n",
    "\n",
    "california_housing_dataframe = california_housing_dataframe.reindex(\n",
    "    np.random.permutation(california_housing_dataframe.index)\n",
    ")\n",
    "\n",
    "california_housing_dataframe[\"median_house_value\"] /= 1000.0\n",
    "california_housing_dataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HzzlSs3PtTmt",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## EDA\n",
    "\n",
    "Посмотрим на данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "cellView": "both",
    "colab": {
     "test": {
      "output": "ignore",
      "timeout": 600
     }
    },
    "colab_type": "code",
    "id": "gzb10yoVrydW",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>median_house_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>17000.0</td>\n",
       "      <td>17000.0</td>\n",
       "      <td>17000.0</td>\n",
       "      <td>17000.0</td>\n",
       "      <td>17000.0</td>\n",
       "      <td>17000.0</td>\n",
       "      <td>17000.0</td>\n",
       "      <td>17000.0</td>\n",
       "      <td>17000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-119.6</td>\n",
       "      <td>35.6</td>\n",
       "      <td>28.6</td>\n",
       "      <td>2643.7</td>\n",
       "      <td>539.4</td>\n",
       "      <td>1429.6</td>\n",
       "      <td>501.2</td>\n",
       "      <td>3.9</td>\n",
       "      <td>207.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>12.6</td>\n",
       "      <td>2179.9</td>\n",
       "      <td>421.5</td>\n",
       "      <td>1147.9</td>\n",
       "      <td>384.5</td>\n",
       "      <td>1.9</td>\n",
       "      <td>116.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-124.3</td>\n",
       "      <td>32.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-121.8</td>\n",
       "      <td>33.9</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1462.0</td>\n",
       "      <td>297.0</td>\n",
       "      <td>790.0</td>\n",
       "      <td>282.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>119.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-118.5</td>\n",
       "      <td>34.2</td>\n",
       "      <td>29.0</td>\n",
       "      <td>2127.0</td>\n",
       "      <td>434.0</td>\n",
       "      <td>1167.0</td>\n",
       "      <td>409.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>180.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>-118.0</td>\n",
       "      <td>37.7</td>\n",
       "      <td>37.0</td>\n",
       "      <td>3151.2</td>\n",
       "      <td>648.2</td>\n",
       "      <td>1721.0</td>\n",
       "      <td>605.2</td>\n",
       "      <td>4.8</td>\n",
       "      <td>265.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>-114.3</td>\n",
       "      <td>42.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>37937.0</td>\n",
       "      <td>6445.0</td>\n",
       "      <td>35682.0</td>\n",
       "      <td>6082.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>500.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
       "count    17000.0   17000.0             17000.0      17000.0         17000.0   \n",
       "mean      -119.6      35.6                28.6       2643.7           539.4   \n",
       "std          2.0       2.1                12.6       2179.9           421.5   \n",
       "min       -124.3      32.5                 1.0          2.0             1.0   \n",
       "25%       -121.8      33.9                18.0       1462.0           297.0   \n",
       "50%       -118.5      34.2                29.0       2127.0           434.0   \n",
       "75%       -118.0      37.7                37.0       3151.2           648.2   \n",
       "max       -114.3      42.0                52.0      37937.0          6445.0   \n",
       "\n",
       "       population  households  median_income  median_house_value  \n",
       "count     17000.0     17000.0        17000.0             17000.0  \n",
       "mean       1429.6       501.2            3.9               207.3  \n",
       "std        1147.9       384.5            1.9               116.0  \n",
       "min           3.0         1.0            0.5                15.0  \n",
       "25%         790.0       282.0            2.6               119.4  \n",
       "50%        1167.0       409.0            3.5               180.4  \n",
       "75%        1721.0       605.2            4.8               265.0  \n",
       "max       35682.0      6082.0           15.0               500.0  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "california_housing_dataframe.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Lr6wYl2bt2Ep",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Первая модель\n",
    "\n",
    "В этом задании требуется предсказать стоимовть жилья (`median_house_value`).\n",
    "\n",
    "Мы будем делать это с помощью [LinearRegressor](https://www.tensorflow.org/api_docs/python/tf/estimator/LinearRegressor) и [tf estimators](https://www.tensorflow.org/get_started/estimator)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UMl3qrU5MGV6"
   },
   "source": [
    "### 1. Определяем target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l1NvvNkH8Kbt"
   },
   "outputs": [],
   "source": [
    "targets = california_housing_dataframe[\"median_house_value\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-0IztwdK2f3F"
   },
   "source": [
    "### 2. Определяем входы в модель"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S5M5j6xSCHxx"
   },
   "source": [
    "С помощью [Dataset API](https://www.tensorflow.org/programmers_guide/datasets) и [Feature columns](https://www.tensorflow.org/guide/feature_columns) мы с легкостью определяем, как данные будут подаваться в модель."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RKZ9zNcHJtwc"
   },
   "outputs": [],
   "source": [
    "def my_input_fn(features, targets, batch_size=1, shuffle=True, num_epochs=None):\n",
    "    \n",
    "    # ключ total_rooms присутствует в features\n",
    "    features = {key: np.array(value) for key, value in dict(features).items()}                                           \n",
    " \n",
    "    ds = tf.data.Dataset.from_tensor_slices((features, targets))\n",
    "    # будем выдавать данные батчами в течение num_epochs эпох\n",
    "    ds = ds.batch(batch_size).repeat(num_epochs)\n",
    "    \n",
    "    if shuffle:\n",
    "        # делаем шафл только во время обучения\n",
    "        # сможете ответить, зачем нужен шафл данных?\n",
    "        ds = ds.shuffle(buffer_size=10000)\n",
    "\n",
    "    return ds\n",
    "\n",
    "my_feature = california_housing_dataframe[[\"total_rooms\"]]\n",
    "# по ключу \"total_rooms\" feature_column будет вытаскивать из tf.data.Dataset нужные фичи\n",
    "feature_columns = [tf.feature_column.numeric_column(\"total_rooms\", shape=(1,))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4M-rTFHL2UkA"
   },
   "source": [
    "### 3. Определяем Модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.00001\n",
    "my_optimizer = tf.train.AdamOptimizer(learning_rate=lr)\n",
    "\n",
    "# посмотрите, какие аргументы принимает LinearRegressor\n",
    "linear_regressor = tf.estimator.LinearRegressor(\n",
    "    feature_columns=feature_columns,\n",
    "    optimizer=my_optimizer\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4YS50CQb2ooO"
   },
   "source": [
    "### 4. Обучаем модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5M-Kt6w8U803"
   },
   "outputs": [],
   "source": [
    "_ = linear_regressor.train(\n",
    "    input_fn = lambda: my_input_fn(my_feature, targets),\n",
    "    steps=100  # 1 step -- это проход по одному батчу\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7Nwxqxlx2sOv"
   },
   "source": [
    "### 5. Считаем качество"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (on training data): 55630.276\n",
      "Root Mean Squared Error (on training data): 235.861\n"
     ]
    }
   ],
   "source": [
    "prediction_input_fn = lambda: my_input_fn(my_feature, targets, num_epochs=1, shuffle=False)\n",
    "# питоновский генератор\n",
    "predictions = linear_regressor.predict(input_fn=prediction_input_fn)\n",
    "\n",
    "# переводим в numpy\n",
    "predictions = np.array([item['predictions'][0] for item in predictions])\n",
    "\n",
    "# считаем метрики\n",
    "mean_squared_error = metrics.mean_squared_error(predictions, targets)\n",
    "root_mean_squared_error = np.sqrt(mean_squared_error)\n",
    "\n",
    "print(\"Mean Squared Error (on training data): %0.3f\" % mean_squared_error)\n",
    "print(\"Root Mean Squared Error (on training data): %0.3f\" % root_mean_squared_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AZWF67uv0HTG",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Перебор гиперпараметров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wgSMeD5UU81N"
   },
   "outputs": [],
   "source": [
    "def train_model(learning_rate, num_epochs, batch_size, input_feature=\"total_rooms\"):\n",
    "\n",
    "    my_feature_data = california_housing_dataframe[[input_feature]]\n",
    "    targets = california_housing_dataframe[\"median_house_value\"]\n",
    "\n",
    "    # Create feature columns.\n",
    "    feature_columns = [tf.feature_column.numeric_column(input_feature, shape=(1,))]\n",
    "\n",
    "    # Create input functions.\n",
    "    training_input_fn = lambda: my_input_fn(my_feature_data, targets, batch_size=batch_size, num_epochs=num_epochs)\n",
    "    prediction_input_fn = lambda: my_input_fn(my_feature_data, targets, num_epochs=1, shuffle=False)\n",
    "\n",
    "    # Create a linear regressor object.\n",
    "    my_optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "    my_optimizer = tf.contrib.estimator.clip_gradients_by_norm(my_optimizer, 5.0)\n",
    "\n",
    "    linear_regressor = tf.estimator.LinearRegressor(\n",
    "      feature_columns=feature_columns,\n",
    "      optimizer=my_optimizer\n",
    "    )\n",
    "\n",
    "    print(\"Training model...\")\n",
    "    linear_regressor.train(input_fn=training_input_fn)\n",
    "\n",
    "    predictions = linear_regressor.predict(input_fn=prediction_input_fn)\n",
    "    predictions = np.array([item['predictions'][0] for item in predictions])\n",
    "\n",
    "    root_mean_squared_error = np.sqrt(metrics.mean_squared_error(predictions, targets))\n",
    "\n",
    "    print(\"Final RMSE (on training data): %0.2f\" % root_mean_squared_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kg8A4ArBU81Q"
   },
   "source": [
    "## Задание 1 (2 балла)\n",
    "\n",
    "Попробуйте поиграть с гиперпараметрами и достигнуть $RMSE \\leq 180$\n",
    "\n",
    "Также можно попробовать:\n",
    "1. Другой оптимайзер ([здесь](https://www.tensorflow.org/api_docs/python/tf/train) можно посмотреть, какие бывают)\n",
    "2. Комбинацию фичей (**feature_columns** -- это list, в котором несколько tf.feature_column.numeric_column)\n",
    "3. Поиграть с аргументами модели (посмотрите, какие аргументы есть у LinearRegressor)\n",
    "\n",
    "p.s.\n",
    "Попробуйте переписать функцию `train_model`, чтобы было удобней изменять параметры модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "cellView": "both",
    "colab": {
     "test": {
      "output": "ignore",
      "timeout": 600
     }
    },
    "colab_type": "code",
    "id": "UzoZUSdLIolF",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n",
      "Final RMSE (on training data): 206.85\n"
     ]
    }
   ],
   "source": [
    "# пример обучения модели\n",
    "train_model(\n",
    "    learning_rate=0.00001,\n",
    "    num_epochs=1,\n",
    "    batch_size=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n",
      "Final RMSE (on training data): 168.42\n",
      "Better result:\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "# пример обучения модели\n",
    "#уменьшим LR, увеличим колво эпох и размер батча(довольно очевидные шаги)\n",
    "train_model(\n",
    "    learning_rate=0.001,\n",
    "    num_epochs=5,\n",
    "    batch_size=5\n",
    ")\n",
    "print(\"Better result:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GpV-uF_cBCBU",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Задание 2 (2 балла)\n",
    "\n",
    "Попробуйте подать в модель другие фичи и достигнуть $RMSE \\leq 170$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft = [\"housing_median_age\",\"households\", \"total_rooms\", \"total_bedrooms\", \"population\", \"median_income\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_train_model(learning_rate, num_epochs, batch_size, input_feature):\n",
    "    #изменил подачу признаков\n",
    "    \n",
    "    my_feature_data = california_housing_dataframe[input_feature]\n",
    "    targets = california_housing_dataframe[\"median_house_value\"]\n",
    "\n",
    "    # Create feature columns.\n",
    "    #предобработка\n",
    "    feature_columns = [tf.feature_column.numeric_column(x, shape=(1,)) for x in input_feature]\n",
    "\n",
    "    # Create input functions.\n",
    "    training_input_fn = lambda: my_input_fn(my_feature_data, targets, batch_size=batch_size, num_epochs=num_epochs)\n",
    "    prediction_input_fn = lambda: my_input_fn(my_feature_data, targets, num_epochs=1, shuffle=False)\n",
    "\n",
    "    # Create a linear regressor object.\n",
    "    my_optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "    my_optimizer = tf.contrib.estimator.clip_gradients_by_norm(my_optimizer, 5.0)\n",
    "\n",
    "    linear_regressor = tf.estimator.LinearRegressor(\n",
    "      feature_columns=feature_columns,\n",
    "      optimizer=my_optimizer\n",
    "    )\n",
    "\n",
    "    print(\"Training model...\")\n",
    "    linear_regressor.train(input_fn=training_input_fn)\n",
    "\n",
    "    predictions = linear_regressor.predict(input_fn=prediction_input_fn)\n",
    "    predictions = np.array([item['predictions'][0] for item in predictions])\n",
    "\n",
    "    root_mean_squared_error = np.sqrt(metrics.mean_squared_error(predictions, targets))\n",
    "\n",
    "    print(\"Final RMSE (on training data): %0.2f\" % root_mean_squared_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n",
      "Final RMSE (on training data): 161.64\n"
     ]
    }
   ],
   "source": [
    "# пример обучения модели\n",
    "my_train_model(\n",
    "    # change lr to 0.01\n",
    "    learning_rate=0.001,\n",
    "    #epochs = 5\n",
    "    num_epochs=10,\n",
    "    batch_size=5,\n",
    "    input_feature = ft\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 3 (2 балла)\n",
    "\n",
    "Вместо `tf.estimator.LinearRegressor` попробуйте применить другую модель и достигнуть $RMSE \\leq 160$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_train_model(learning_rate, num_epochs, batch_size, input_feature):\n",
    "    #изменил подачу признаков\n",
    "    \n",
    "    my_feature_data = california_housing_dataframe[input_feature]\n",
    "    targets = california_housing_dataframe[\"median_house_value\"]\n",
    "\n",
    "    # Create feature columns.\n",
    "    #предобработка\n",
    "    feature_columns = [tf.feature_column.numeric_column(x, shape=(1,)) for x in input_feature]\n",
    "\n",
    "    # Create input functions.\n",
    "    training_input_fn = lambda: my_input_fn(my_feature_data, targets, batch_size=batch_size, num_epochs=num_epochs)\n",
    "    prediction_input_fn = lambda: my_input_fn(my_feature_data, targets, num_epochs=1, shuffle=False)\n",
    "\n",
    "    # Create a linear regressor object.\n",
    "    my_optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "    my_optimizer = tf.contrib.estimator.clip_gradients_by_norm(my_optimizer, 5.0)\n",
    "\n",
    "    #не будем мудрить, просто поставим DNNLinear и получим отличный скор\n",
    "    linear_regressor = tf.estimator.DNNLinearCombinedRegressor(linear_feature_columns= feature_columns)\n",
    "\n",
    "    print(\"Training model...\")\n",
    "    linear_regressor.train(input_fn=training_input_fn)\n",
    "\n",
    "    predictions = linear_regressor.predict(input_fn=prediction_input_fn)\n",
    "    predictions = np.array([item['predictions'][0] for item in predictions])\n",
    "\n",
    "    root_mean_squared_error = np.sqrt(metrics.mean_squared_error(predictions, targets))\n",
    "\n",
    "    print(\"Final RMSE (on training data): %0.2f\" % root_mean_squared_error)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n",
      "Final RMSE (on training data): 146.98\n"
     ]
    }
   ],
   "source": [
    "my_train_model(\n",
    "    # change lr to 0.01\n",
    "    learning_rate=0.001,\n",
    "    #epochs = 5\n",
    "    num_epochs=10,\n",
    "    batch_size=5,\n",
    "    input_feature = ft\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "JndnmDMp66FL",
    "ajVM7rkoYXeL",
    "ci1ISxxrZ7v0"
   ],
   "name": "first_steps_with_tensor_flow.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
